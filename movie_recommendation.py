# -*- coding: utf-8 -*-
"""Movie Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uMqWIt39cnyURiNGlS7zRINyHnlkRlPc
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from wordcloud import WordCloud
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

#loading the dataset to a pandas dataframe
df = pd.read_csv("movies.csv")

df.shape

df.head()

df.info()

#filter the required columns for recommendation
required_columns = ["genres", "keywords", "overview", "title", "director"]

df = df[required_columns]

df.shape

df.head()

#checking for missing values
df.info()

#dropping the null value
df = df.dropna().reset_index(drop=True)

df.info()

#Combing the column that we have not title cause title is the target value
df['combined-info'] = df['genres'] + ' ' + df['keywords'] + ' ' + df['overview'] + ' ' + df['director']

df.head()

data = df[['title', 'combined-info']]

data.head()

#WordCloud for movie content (This is just for the data visualization, optional)
combined_text = " ".join(df['combined-info'])
wordcloud = WordCloud(width=600, height=500, background_color="white").generate(combined_text)

#WordCloud to visualize the most common words in the movie content
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Most Common Words in combined-info movie content")
plt.show()

# download nltk data
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))
stop_words

def preprocess_text(text):
    #Remove special characters and numbers
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    #Convert to lowercase
    text = text.lower()
    #Tokenize and remove stopwords
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word not in stop_words]
    return " ".join(tokens)

#Applying preprocessing to the movie content
data['cleaned-movie-info'] = df['combined-info'].apply(preprocess_text)

data.head()

#Vectorization with TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=4500)
tfidf_matrix = tfidf_vectorizer.fit_transform(data['cleaned-movie-info'])

#Compute Cosine Similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(cosine_sim[0])
print(len(cosine_sim[0])) # similarity with all the movie
#print(cosine_sim

#Recommendation Function
def recommend_movies(movie_name, cosine_sim=cosine_sim, df=data, top_n=7):
    #finding the index of the movie
    idx = df[df['title'].str.lower() == movie_name.lower()].index
    if len(idx) == 0:
        return "Movie not found in the dataset!"
    idx = idx[0]

    #geting similarity scores
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True) # Sorted on the increasing similarity present in 1st index
    sim_scores = sim_scores[1:top_n+1] # removing the same movie

    #getting movie indices
    movie_indices = [i[0] for i in sim_scores]

    #returning top n similar movies
    return df[['title']].iloc[movie_indices]

data["title"]

row_index = df[df['title'] == "The Dark Knight Rises"].index
print(row_index)

movie_name = data["title"][3]
print(movie_name)

#Example Recommendation
print(f"Recommendations for the Movie {movie_name}")
recommendations = recommend_movies(movie_name)
print(recommendations)